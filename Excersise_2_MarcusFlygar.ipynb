{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7vBP5eRL1gWCV3nnBhwNd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcusflygar1-hash/AI_Course_Submissions_real/blob/main/Excersise_2_MarcusFlygar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbV-mF9RZDUu"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import dataset\n",
        "url = 'https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/master/Exercise_2_regression_model/Exercise2BusData.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "usc1WmIJZjqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "EvMz1XVbmzA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Arrival_time', 'Stop_id','Bus_id','Line_id'], axis=1) #These columns of information is not needed for the prediction of delay in busses.\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "IssWkexAZz7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "id": "YHih_wQQboOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "LDF4lSGvb_Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "corr_matrix['Arrival_delay'].sort_values(ascending=False) #The correlation matrix focuses on the correlation between the remaining columns to Arrival Delay"
      ],
      "metadata": {
        "id": "C5E8mNOLcELt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the upstream stop delay is heavily correlated to the arrival delay, however this is not true for the remaining independent variables."
      ],
      "metadata": {
        "id": "wZUmcdbHfH47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.drop('Arrival_delay', axis=1)\n",
        "y = df['Arrival_delay']\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "LsSVaIfQezn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason as to why we set the test_size = 0,2 is that this will devide the model into 80% training data and 20% of the data to test this on."
      ],
      "metadata": {
        "id": "GEWNZ8Hef2If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "y_pred = lin_reg.predict(X_test)"
      ],
      "metadata": {
        "id": "AAbB17e7gBF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have trained and tested the data set, now we will evaluate the model and see if it performs well."
      ],
      "metadata": {
        "id": "gJaDyaFAgXjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error, r2_score\n",
        "lin_mse = mean_squared_error(y_test, y_pred)\n",
        "lin_mae = mean_absolute_error(y_test, y_pred)\n",
        "lin_rmse = root_mean_squared_error(y_test, y_pred)\n",
        "lin_r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {lin_mse}\")\n",
        "print(f\"Mean Absolute Error: {lin_mae}\")\n",
        "print(f\"Root Mean Squared Error: {lin_rmse}\")\n",
        "print(f\"R2 Score: {lin_r2}\")"
      ],
      "metadata": {
        "id": "vL3uhh8PgL4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)  # Plot actual vs. predicted values\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Actual vs. Predicted Values\")\n",
        "\n",
        "# Add a diagonal line for reference (perfect predictions)\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', lw=2)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dOUBpnfQwqRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have performed a Linear regression together with training and test data and evaluated it. It is time to perform a linear regression witht the XgBoost package.  "
      ],
      "metadata": {
        "id": "sOnRHV3sls53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost BusDelay"
      ],
      "metadata": {
        "id": "twV0eT4ylpz_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mJ3FkqILlzT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting upp the features and labels into a Dmatrix so XGBoost can read it\n",
        "#(Maybe idk, but I read online that you should do this)\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)"
      ],
      "metadata": {
        "id": "iWalZy4GmB_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the booster parameters, these are just generic, I might play around\n",
        "# with them later if needed\n",
        "param_xg = {'max_depth':3,\n",
        "            'eta':0.1,\n",
        "            'objective': 'reg:squarederror',\n",
        "            'seed': 42,\n",
        "            'nthread':4,\n",
        "            'eval_metric':'rmse'}\n"
      ],
      "metadata": {
        "id": "MnkA58I72TVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evallist = [(dtrain, 'train'), (dtest, 'eval')]"
      ],
      "metadata": {
        "id": "WlTQnXn92vXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here I set upp the training and saving the model.\n",
        "# This so I can evaluate it later\n",
        "num_round = 100 # Updated number from 10 to 100, to get better results.\n",
        "bst = xgb.train(param_xg, dtrain, num_round, evallist)\n",
        "bst.save_model('xgboost_model.model')\n"
      ],
      "metadata": {
        "id": "5x2aHIed3ICy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bst = xgb.Booster({'nthread': 4})  # load model\n",
        "bst.load_model('xgboost_model.model')"
      ],
      "metadata": {
        "id": "CE9T71zmiNH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting..\n",
        "data = np.random.rand(5, 10)  # 5 entities, each contains 10 features\n",
        "dtest = xgb.DMatrix(X_test)\n",
        "y_pred_xgb = bst.predict(dtest)"
      ],
      "metadata": {
        "id": "CzUXkKLj3jhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Results we can evaulate, MSE, MAE, RMSE, R2.\n",
        "xgb_mse = mean_squared_error(y_test, y_pred_xgb)\n",
        "xgb_mae = mean_absolute_error(y_pred, y_pred_xgb)\n",
        "xgb_rmse = root_mean_squared_error(y_test, y_pred_xgb)\n",
        "xgb_r2 = r2_score(y_test, y_pred_xgb)\n",
        "# Printing the results\n",
        "print(f\"Mean Squared Error: {xgb_mse}\")\n",
        "print(f\"Mean Absolute Error: {xgb_mae}\")\n",
        "print(f\"Root Mean Squared Error: {xgb_rmse}\")\n",
        "print(f\"R2 Score: {xgb_r2}\")"
      ],
      "metadata": {
        "id": "01vKrgEz47Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb.plot_importance(bst) # This will show us the attributes that impact the models score the most.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jKCtzpKusO_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we plot the figure to see how we did with the XGBoost."
      ],
      "metadata": {
        "id": "ujoyGRhZ60lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OBS This code for the plotting is from taken the Exercises.\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred_xgb, alpha=0.5)  # Plot actual vs. predicted values\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Actual vs. Predicted Values\")\n",
        "\n",
        "# Add a diagonal line for reference (perfect predictions)\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', lw=2)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PWp_PoKS6dSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets try to improve on this model by using a GridSearch"
      ],
      "metadata": {
        "id": "vgQswKRDqGDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here a Grid Search will be used to improve the performance of the XGBooster\n",
        "\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "X, y = df.drop('Arrival_delay', axis=1), df['Arrival_delay']\n",
        "\n",
        "# Split data into train and test sets..\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# parameter grid\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'learning_rate': [0.01, 0.1, 0.3]\n",
        "}\n",
        "\n",
        "\n",
        "# Create XGBoost regressor\n",
        "\n",
        "xgb_model = XGBRegressor(n_estimators=200, objective='reg:squarederror', random_state=42)\n",
        "\n",
        "\n",
        "# execute the grid search\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#Print the results\n",
        "\n",
        "print(f\"The combination of parameters that provides the highest score: {grid_search.best_params_}\")\n",
        "print(f\"Highest score: {grid_search.best_score_}\")"
      ],
      "metadata": {
        "id": "Yvd7e4OaqEwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After playing around the parameters with the grid search, I did not find any improvements"
      ],
      "metadata": {
        "id": "Tt2PwVG8rK-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bike-sharing."
      ],
      "metadata": {
        "id": "ehrrdvUljxnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_bike = 'https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/master/Exercise_2_regression_model/Exercise2BikeSharing.csv'\n",
        "df_bike = pd.read_csv(url_bike)\n",
        "df_bike.head(10)"
      ],
      "metadata": {
        "id": "7LLO1vFh6g2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bike.info()"
      ],
      "metadata": {
        "id": "261OmiAFkrez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bike = df_bike.drop(['dteday','instant','casual','registered'], axis=1) #Drop the date as it is an uncompatible datatype\n",
        "corr_matrix_bike = df_bike.corr() #Creates a correlation matrix\n",
        "corr_matrix_bike['cnt'].sort_values(ascending=False) #The correlation matrix focuses on the correlation between the remaining columns to count, aka count of total rental bikes including both casual and registered"
      ],
      "metadata": {
        "id": "1J4NEyjnkMzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4839456e"
      },
      "source": [
        "x_bike = df_bike.drop('cnt', axis=1) # Dropping count as we want this as our predictor\n",
        "y_bike = df_bike['cnt']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into train and test data sets.\n",
        "X_train_bike, X_test_bike, y_train_bike, y_test_bike = train_test_split(x_bike,y_bike, test_size=0.2, random_state=42) #WE use a  80/20 split. Common practice in train / test splitted data.\n",
        "#Training.\n",
        "bike_reg = LinearRegression()\n",
        "bike_reg.fit(X_train_bike, y_train_bike)\n",
        "y_pred_bike = bike_reg.predict(X_test_bike)"
      ],
      "metadata": {
        "id": "AuwFfCiBRI-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calc mse, mae.. etc..\n",
        "bike_mse = mean_squared_error(y_test_bike, y_pred_bike)\n",
        "bike_mae = mean_absolute_error(y_test_bike, y_pred_bike)\n",
        "bike_rmse = root_mean_squared_error(y_test_bike, y_pred_bike)\n",
        "bike_r2 = r2_score(y_test_bike, y_pred_bike)\n",
        "#Print results.\n",
        "print(f\"Mean Squared Error: {bike_mse}\")\n",
        "print(f\"Mean Absolute Error: {bike_mae}\")\n",
        "print(f\"Root Mean Squared Error: {bike_rmse}\")\n",
        "print(f\"R2 Score: {bike_r2}\")\n"
      ],
      "metadata": {
        "id": "y95sboLZT1pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test_bike, y_pred_bike, alpha=0.5)\n",
        "\n",
        "\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Actual vs. Predicted Values\")\n",
        "plt.plot([min(y_test_bike), max(y_test_bike)], [min(y_test_bike), max(y_test_bike)], linestyle='--', color='red', lw=2)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jw-y4LaaXqXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see these results are not very good. Therefore we will move on to a more advanced model. Like a SVM and a XGBoost."
      ],
      "metadata": {
        "id": "qR27SXueUQmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining and trainging the XGBoost model.\n",
        "X,y = x_bike, y_bike\n",
        "dtrain = xgb.DMatrix(X_train_bike, label=y_train_bike)\n",
        "dtest = xgb.DMatrix(X_test_bike, label=y_test_bike)\n",
        "\n",
        "vibe = xgb.XGBRegressor()\n",
        "vibe.fit(X_train_bike, y_train_bike)\n",
        "y_pred_bike_xgb = vibe.predict(X_test_bike)\n",
        "vibe.save_model('xgboost_model_bike.model')"
      ],
      "metadata": {
        "id": "AwFcwjp6UDnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculation of evaluation metrics.\n",
        "xgb_bike_mse = mean_squared_error(y_test_bike, y_pred_bike_xgb)\n",
        "xgb_bike_mae = mean_absolute_error(y_test_bike, y_pred_bike_xgb)\n",
        "xgb_bike_rmse = root_mean_squared_error(y_test_bike, y_pred_bike_xgb)\n",
        "xgb_bike_r2 = r2_score(y_test_bike, y_pred_bike_xgb)\n",
        "\n",
        "#Print results.\n",
        "print(f\"XGBoost Mean Squared Error: {xgb_bike_mse}\")\n",
        "print(f\"XGBoost Mean Absolute Error: {xgb_bike_mae}\")\n",
        "print(f\"XGBoost Root Mean Squared Error: {xgb_bike_rmse}\")\n",
        "print(f\"XGBoost R2 Score: {xgb_bike_r2}\")"
      ],
      "metadata": {
        "id": "a7JWROk2VDRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb.plot_importance(vibe) # This will show us the attributes that impact the models score the most.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "svtV5halWPdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test_bike, y_pred_bike_xgb, alpha=0.5)\n",
        "\n",
        "\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Actual vs. Predicted Values\")\n",
        "plt.plot([min(y_test_bike), max(y_test_bike)], [min(y_test_bike), max(y_test_bike)], linestyle='--', color='red', lw=2)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kGJj1LvbW8Bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bike Sharing SVM Model\n",
        "\n"
      ],
      "metadata": {
        "id": "UzVp0Vb0eeAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importting and training the model\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "svm_reg_bike = SVR()\n",
        "svm_reg_bike.fit(X_train_bike, y_train_bike)"
      ],
      "metadata": {
        "id": "l5KMPJWUehjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d355bd4f"
      },
      "source": [
        "#Scaling as SVM models are sensetive to features scales\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_bike = scaler.fit_transform(X_train_bike)\n",
        "X_test_scaled_bike = scaler.transform(X_test_bike)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the SVM Model\n",
        "svr_bike = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
        "svr_bike.fit(X_train_scaled_bike, y_train_bike)"
      ],
      "metadata": {
        "id": "AugByzd3lMD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-T_krvclY_A"
      },
      "source": [
        "#predicting the data\n",
        "y_pred_bike_svm = svr_bike.predict(X_test_scaled_bike)\n",
        "\n",
        "#calculating our evaluation metrics\n",
        "bike_svm_mse = mean_squared_error(y_test_bike, y_pred_bike_svm)\n",
        "bike_svm_mae = mean_absolute_error(y_test_bike, y_pred_bike_svm)\n",
        "bike_svm_rmse = root_mean_squared_error(y_test_bike, y_pred_bike_svm)\n",
        "bike_svm_r2 = r2_score(y_test_bike, y_pred_bike_svm)\n",
        " # Print results\n",
        "print(f\"SVM Mean Squared Error: {bike_svm_mse}\")\n",
        "print(f\"SVM Mean Absolute Error: {bike_svm_mae}\")\n",
        "print(f\"SVM Root Mean Squared Error: {bike_svm_rmse}\")\n",
        "print(f\"SVM R2 Score: {bike_svm_r2}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a6ebb6a"
      },
      "source": [
        "# Plotting the actual vs. predicted values for the SVM model\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test_bike, y_pred_bike_svm, alpha=0.7)\n",
        "\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Actual vs. Predicted Values for SVM\")\n",
        "\n",
        "plt.plot([min(y_test_bike), max(y_test_bike)], [min(y_test_bike), max(y_test_bike)], linestyle='--', color='orange', lw=2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A basic SVM model without any kind of hypertuning etc. works less well than a basic XGBoost and normal linear regression."
      ],
      "metadata": {
        "id": "0zynSRALoErP"
      }
    }
  ]
}