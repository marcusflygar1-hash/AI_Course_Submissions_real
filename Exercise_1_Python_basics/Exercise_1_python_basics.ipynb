{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br3JSUhb__P6"
      },
      "source": [
        "# Exercise - Part 2.1 - Python basics\n",
        "\n",
        "Adapted tutorial from the chapter 3 of the book:\n",
        "\n",
        "De Ponteves, H. (2019). AI Crash Course: A fun and hands-on introduction to machine learning, reinforcement learning, deep learning, and artificial intelligence with Python. Packt Publishing Ltd.\n",
        "\n",
        "You can follow original instructions from the link: [chapter 3 tutorial](https://learning.oreilly.com/library/view/ai-crash-course/9781838645359/Text/Chapter_3.xhtml#sigil_toc_id_40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc8sDiw2Yua0"
      },
      "source": [
        "First, let's try a simple command to display (print) text on the screen, like \"Hello world!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNAVQwCvYuuZ"
      },
      "outputs": [],
      "source": [
        "print(\"Hello world!, test whadd up, bro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE5-fCz0dIZF"
      },
      "source": [
        "In Python you can also add comments to describe what your code does or just notes for yourself, starting with '**#**' all after it is not executed as a command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p22GVnzkB9bT"
      },
      "outputs": [],
      "source": [
        "# this is a print\n",
        "print('Hello world!') # prints Hello world!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH4PAQUWClRe"
      },
      "source": [
        "**Variables** pointers to values/objects allocated somewhere in the memory. By referring to that variable by defined name, the value/object is retrieved from memory, or a new value is assigned. In Python, you do not need to specify the variable's data type, which is common in languages such Java, C++."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuR0BC7lUttN"
      },
      "outputs": [],
      "source": [
        "x = 3\n",
        "y = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aJc7EKxVLqJ"
      },
      "source": [
        "Here we assign value 3 to variable 'x' and value 5 to variable 'y'. So from this point in code always, as long as you do not change the value, when you refer to variable 'x' it will have value 5 and variable 'y' the value 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcq-0oO8VnE7"
      },
      "outputs": [],
      "source": [
        "print(f\"value in 'x' is {x}\")\n",
        "print(\"value in 'y' is\", y)\n",
        "print('x + y =', x + y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Byix68yVmsk"
      },
      "source": [
        "Variables can be of different data types, such as integers (2, 3, 4, ...), Float (2.3241213, 4.21), strings (\"Hello\"), chars ('a', 'b'), and many different objects (arrays, tables, sets of data records). It simplifies your coding by referring to the same data by same-shorter-familiar-reference in the code. You do not want to specify always the array of 1000 records, especially if you will refer to them many times. What you want is to simplify your life and do it once. Thus, you may assign to a variable list of records, for example *my_input_data*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t63V1zEUyIj"
      },
      "source": [
        "## Lists and Arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MekjEHKKX5SV"
      },
      "outputs": [],
      "source": [
        "my_input_data = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYA-qKxIX1i0"
      },
      "source": [
        "In Python, you can access the value at a specific index of a list by specifying an index, such as *my_input_data[0]*. Note that indexing in Python starts from 0, last object index is *my_input_data[-1]* or *my_input_data[len(my_input_data) - 1]*, where *len(my_input_data)* is the size of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXCL7poNSYpK"
      },
      "outputs": [],
      "source": [
        "print('first item', my_input_data[0])\n",
        "print('last item', my_input_data[-1])\n",
        "print('last item', my_input_data[len(my_input_data) - 1])\n",
        "print('size of list', len(my_input_data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_input_data[-1] - my_input_data[-2])"
      ],
      "metadata": {
        "id": "MpxCeqXSBxP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvT47L_VTOYH"
      },
      "source": [
        "You may add new items at the end by calling the list's *append()* function. The item can be deleted by calling the command 'del' and specifying the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv06LeG5TVXD"
      },
      "outputs": [],
      "source": [
        "my_input_data.append(21)\n",
        "del my_input_data[0]\n",
        "print(my_input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxhKlJmL-UFA"
      },
      "source": [
        "Assign value at certain position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Br54YKA-UFA"
      },
      "outputs": [],
      "source": [
        "my_input_data[2] = 1000\n",
        "print(my_input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvsliHT9Utj0"
      },
      "source": [
        "## Matrices\n",
        "In this course, we will often use tables, matrices, or multidimensional matrices. For this, we use *numpy* library. The example below creates the matrix 3x3 filled by zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2i494-hUmQY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "matrix_0 = np.zeros((3,3))\n",
        "print(matrix_0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SCLjB3KU9H6"
      },
      "source": [
        "Here first index *'x'* of *matrix_0[x,y]* is for rows while second *'y'* is for column of matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bISpdwQlWLv1"
      },
      "outputs": [],
      "source": [
        "matrix_0[0,0] = 1\n",
        "matrix_0[0,1] = 2\n",
        "matrix_0[0,2] = 3\n",
        "matrix_0[1,0] = 4\n",
        "matrix_0[1,1] = 5\n",
        "matrix_0[1,2] = 6\n",
        "matrix_0[2,0] = 7\n",
        "matrix_0[2,1] = 8\n",
        "matrix_0[2,2] = 9\n",
        "print(matrix_0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-rMdN6GW5ZC"
      },
      "source": [
        "Below, we show the calculation of the mean. If you use some function for the first time, checking the documentation, its inputs and outputs, and validating the results is good practice: [mean function definition](https://numpy.org/doc/stable/reference/generated/numpy.mean.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "et1B4E4aXFj9"
      },
      "outputs": [],
      "source": [
        "matrix_mean = np.mean(matrix_0)\n",
        "matrix_min = np.min(matrix_0)\n",
        "matrix_max = np.max(matrix_0)\n",
        "print(f\"The mean of the matrix is {matrix_mean}\")\n",
        "print(f\"The min of the matrix is {matrix_min}\")\n",
        "print(f\"The max of the matrix is {matrix_max}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbyxnA39Y3s9"
      },
      "source": [
        "Changes and copying of objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "841Jekx3ZKRA"
      },
      "outputs": [],
      "source": [
        "matrix_1 = matrix_0.copy() # create new instance of the object which is copied\n",
        "matrix_2 = matrix_0 # using just assignment command will create only new pointer to existing object, Thus both matrix_0 and matrix_2 point to same object in memory\n",
        "matrix_2[1,1] = 12 # Thus changing the value will result in change for both matrix_0 and matrix_2 becaue they point to same object.\n",
        "print('matrix_0',matrix_0)\n",
        "print('matrix_2',matrix_2)\n",
        "matrix_1[1,1] = np.nan\n",
        "print('matrix_0',matrix_0)\n",
        "print('matrix_1',matrix_1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQL7vurtaXuC"
      },
      "source": [
        "In case there are unknown or NaN values in dataset calling np.mean or np.min will fail or result in NaN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIHTrhTXanNj"
      },
      "outputs": [],
      "source": [
        "print(np.mean(matrix_1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RohwCb1k-UFD"
      },
      "source": [
        "An alternative to still calculate a mean value with the remaining values is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_XPj9LV-UFE"
      },
      "outputs": [],
      "source": [
        "print(np.nanmean(matrix_1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cFITJTdbH4K"
      },
      "source": [
        "Is there any nan value in matrix? use np.isnan()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pQBl-rPbWAS"
      },
      "outputs": [],
      "source": [
        "print(np.isnan(matrix_1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWSu0MxTbbWk"
      },
      "source": [
        "Count them with *np.sum*. Boolean values such True or False they are actully also intepretable as integers: 1:True and 0:False so you can count them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGpdiXiQbgYP"
      },
      "outputs": [],
      "source": [
        "print(np.sum(np.isnan(matrix_1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1aLfCjLbokT"
      },
      "source": [
        "## Constraints IF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_13aBeDbsyb"
      },
      "source": [
        "Help to branch the code based on logical statements ('AND' and 'OR' and their combinations). For example, if there is a NaN value in the dataset, use a different function to calculate the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwdM_kp2b9Fo"
      },
      "outputs": [],
      "source": [
        "if np.sum(np.isnan(matrix_1)) > 0:\n",
        "  print('there is nan value, np.nanmean calculated',np.nanmean(matrix_1))\n",
        "else:\n",
        " print('there is no nan value, np.mean calculated',np.mean(matrix_1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw7uroyUcXYN"
      },
      "source": [
        "Another example with more conditions and multiple cases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKY3sSg4cqME"
      },
      "outputs": [],
      "source": [
        "if np.sum(np.isnan(matrix_1)) == 0:\n",
        "  print('there is no nan value, mean is: ',np.mean(matrix_1))\n",
        "elif np.sum(np.isnan(matrix_1)) > 0 and np.nanmean(matrix_1) < 6:\n",
        "  print('there is a nan value and the mean is less than 6')\n",
        "else:\n",
        "  print('there is a nan value and the mean is greater than or equal to 6')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POu2opiFdix7"
      },
      "source": [
        "## Creating functions\n",
        "You can create your function to simplify scripts and lower repetitions. If some operations consist of blocks of several lines and would be repeated frequently, the recommended practice is to write the function once and call it when needed. For example, lets define a function for calculating the mean with nan or without nan values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml7cMxTke4nV"
      },
      "source": [
        "using above constraints this is how code for calcuting mean for *matrix_0*, *matrix_1*, and *matrix_2* will look:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NQuXznafAwW"
      },
      "outputs": [],
      "source": [
        "if np.sum(np.isnan(matrix_0)) > 0:\n",
        "  print('there is nan value, np.nanmean calculated',np.nanmean(matrix_0))\n",
        "else:\n",
        " print('there is no nan value, np.mean calculated',np.mean(matrix_0))\n",
        "\n",
        "if np.sum(np.isnan(matrix_1)) > 0:\n",
        "  print('there is nan value, np.nanmean calculated',np.nanmean(matrix_1))\n",
        "else:\n",
        " print('there is no nan value, np.mean calculated',np.mean(matrix_1))\n",
        "\n",
        "if np.sum(np.isnan(matrix_2)) > 0:\n",
        "  print('there is nan value, np.nanmean calculated',np.nanmean(matrix_2))\n",
        "else:\n",
        " print('there is no nan value, np.mean calculated',np.mean(matrix_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFNY041WfMLR"
      },
      "source": [
        "Or it can be simplify with calling defined function *calculate_mean*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDZRtbh7eGT4"
      },
      "outputs": [],
      "source": [
        "def calculate_mean(input_matrix):\n",
        "  if np.nansum(np.isnan(input_matrix)) > 0:\n",
        "    print('there is nan value, np.nanmean calculated',np.nanmean(input_matrix))\n",
        "  else:\n",
        "    print('there is no nan value, np.mean calculated',np.mean(input_matrix))\n",
        "\n",
        "calculate_mean(matrix_0)\n",
        "calculate_mean(matrix_1)\n",
        "calculate_mean(matrix_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep49i02Wen1b"
      },
      "source": [
        "So in this case you can just call function *calculate_mean* and simplify your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfeih-hFbB1O"
      },
      "source": [
        "## Loops\n",
        "These are tools that enable you to iterate across arrays and matrices. For example, we show two different ways of looping with the command *'for'* and print the values of the first row:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmIU24MEgWc1"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(matrix_0[0])):\n",
        "  print('In the first row the value for column ',i+1, matrix_0[0, i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqNwyc96hVza"
      },
      "outputs": [],
      "source": [
        "print(matrix_0)\n",
        "first_row_in_matrix_0 = matrix_0[0]\n",
        "i = 1\n",
        "for value_i in first_row_in_matrix_0:\n",
        "  print('In the first row the value for column ', i, value_i)\n",
        "  i +=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dom-2uCb-UFS"
      },
      "source": [
        "# Exercise - Part 2.2. - Loading and Exploring External Data\n",
        "\n",
        "In this part we will load an external data set from a CSV file, explore it with the Python library *pandas* and plot parts of it with the librarby *mathplotlib*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNXVIomx-UFS"
      },
      "source": [
        "## Load data with Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiBg3QpM-UFS"
      },
      "source": [
        "Load the library pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ0DB6xq-UFT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayY-Z8nZ-UFT"
      },
      "source": [
        "Load the dataset in a pandas DataFrame (similar to a Numpy matrix but offers more functionality)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK5icEBj-UFT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Exercise2BusData.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh06I6Y9-UFT"
      },
      "source": [
        "If you are not able to upload the data to colab, you can uncommment these lines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2P-L5Q3-UFT"
      },
      "outputs": [],
      "source": [
        "# url = 'https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/master/Exercise_2_regression_model/Exercise2BusData.csv'\n",
        "# df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3plhU5iN-UFU"
      },
      "source": [
        "Exploring the columns and 10 first rows of the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQExNv67-UFU"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTg0jRVo-UFU"
      },
      "source": [
        "## Selecting specific entries\n",
        "\n",
        "For example, we might be interested in all entries which were to early:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RyiJ0cJ-UFV"
      },
      "outputs": [],
      "source": [
        "df[df[\"Arrival_delay\"] < 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W341ViP-UFV"
      },
      "source": [
        "Combination of filters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KERW8nO-UFV"
      },
      "outputs": [],
      "source": [
        "df[\n",
        "    (df[\"Arrival_delay\"] < 0)\n",
        "    & (df[\"Dwell_time\"] > 30)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9Xmk5f5-UFV"
      },
      "source": [
        "## Analysis of the DataFrame\n",
        "\n",
        "We can for instance calculate the mean arrival delay for each Bus id:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFDQdi44-UFW"
      },
      "outputs": [],
      "source": [
        "df.groupby(\"Bus_id\")[\"Arrival_delay\"].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkIKLFAO-UFW"
      },
      "source": [
        "## Plotting with matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqk_3vnr-UFW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss2UA54s-UFW"
      },
      "source": [
        "We now create a scatter plot plotting the dwell time vs the arrival delay. This can help to uncover relations between the different variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KofXY8jC-UFX"
      },
      "outputs": [],
      "source": [
        "plt.scatter(data=df, x=\"Dwell_time\", y=\"Arrival_delay\")\n",
        "plt.xlabel(\"Dwell_time\")\n",
        "plt.ylabel(\"Arrival_delay\")\n",
        "plt.title(\"Scatter plot of Dwell Time vs Arrival Delay\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF8aSemu-UFY"
      },
      "source": [
        "Other plots that might be helpful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIxjAyWA-UFY"
      },
      "outputs": [],
      "source": [
        "plt.boxplot(df[\"Dwell_time\"])\n",
        "plt.xlabel(\"Dwell_time\")\n",
        "plt.title(\"Box plot of Dwell Time\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKMiuw11Bpww"
      },
      "source": [
        "# Appendix - Part 1 - Example code that might be helpful for the excersises\n",
        "In this part, we will focus on a simple example of applying the ML model to transportation prediction applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWPNM8MCwt5E"
      },
      "source": [
        "As first lets import, install and upgrade libraries we would need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQGXMJMohU8t"
      },
      "outputs": [],
      "source": [
        "# Install packages for colab env\n",
        "!pip install fastparquet # package for reading .parquet data\n",
        "!pip install --upgrade geopandas  # for spatial visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSLhjlsekDQD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nqh3O32B4tl"
      },
      "source": [
        "## Data loading\n",
        "The below code is pulling the open NY taxi trip data from GitHub repository and create pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4VMXdFUkWEI"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset\n",
        "# Two ways to read our data in colab, here we use 2)\n",
        "# 1). upload\n",
        "# 2). clone from github repo\n",
        "\n",
        "\"\"\"\n",
        "# 1). Upload and read data\n",
        "# import files module\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "print(os.listdir())\n",
        "df = pd.read_parquet('NY_taxi_2017Mar_09-11.parquet', engine='fastparquet')\n",
        "\"\"\"\n",
        "\n",
        "# 2). Clone and read data from github repo\n",
        "!git clone https://github.com/georgewanglz2019/Data-Science-and-AI-for-Intelligent-Transport-Systems.git\n",
        "%cd Data-Science-and-AI-for-Intelligent-Transport-Systems\n",
        "print(os.listdir())  #  Gets the files and directories present in current path\n",
        "trips = pd.read_parquet('NY_Taxi_March_2017.parquet', engine='fastparquet')  # extracted trip data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOkOraDPxCgk"
      },
      "source": [
        "And lets check the dataframe *trips* data by examining first two rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcE0ZsvgkdBc"
      },
      "outputs": [],
      "source": [
        "trips.head(2) # show the first 10 lines of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96JK6qM1midI"
      },
      "source": [
        "## Modeling\n",
        "Often, data must be manipulated and processed to the ML model input format. **!!! Note** During the course, you will receive ready datasets or Python scripts for their manipulation to let you focus on exploration and training models. However, you may consider additional manipulation of handling outliers if you identify some in the training process.\n",
        "\n",
        "### Data manipulation\n",
        "Here, we want to aggregate the individual trip records to 15 time intervals. They will be used as the historical dataset for training the ML model and predicting future 15 minutes by allowing the use of observations from 3 prior time intervals in the past back to 45 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wzWq-jommO5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "\n",
        "\"\"\" ************************ DATA MANIPULATING/ORGANIZATION ********************************************\"\"\"\n",
        "# I: Calculate passenger trips per time period per day\n",
        "trips_period = trips.groupby(['DayofYear', 'TimePeriod'])['passenger_count'].sum().reset_index()\n",
        "\n",
        "# II: construct time series\n",
        "# step 1: Construct a template of times\n",
        "time_interval = 15  # 15 min\n",
        "day_start, day_end = (60, 91)   # March, days starting from January 1\n",
        "time_start, time_end = (5 * 60, 23 * 60)   # 5:00-23:00 in minutes\n",
        "unique_days = np.arange(day_start, day_end)\n",
        "unique_time_periods = np.arange(time_start, time_end, time_interval)   # time period with interval 15 minutes\n",
        "list_day, list_time = zip(*[(d, t) for d in unique_days for t in unique_time_periods])\n",
        "\n",
        "ts_template = pd.DataFrame()\n",
        "ts_template = ts_template.assign(DayofYear=list_day, TimePeriod=list_time)\n",
        "\n",
        "# step 2: Merge the observations with the template and fill na zero\n",
        "ts = ts_template.merge(trips_period, on=['DayofYear', 'TimePeriod'], how='left').fillna(0)\n",
        "ts.sort_values(['DayofYear', 'TimePeriod'], inplace=True, ascending=False)\n",
        "\n",
        "# step 3: Create columns for time series of pax counts with time lags (t-1, t-2, t-3, etc.)\n",
        "ts['T'] = ts['passenger_count']\n",
        "ts['T_1'] = ts['T'].shift(-1)\n",
        "ts['T_2'] = ts['T'].shift(-2)\n",
        "ts['T_3'] = ts['T'].shift(-3)\n",
        "print(ts.head())\n",
        "# step 4: Delete the record with day transition time periods\n",
        "del_list = np.arange(time_start, time_start + time_interval * 3, time_interval)\n",
        "\n",
        "ts = ts[~ts.TimePeriod.isin(del_list)]\n",
        "print(ts.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvQ5VFQM00AV"
      },
      "source": [
        "For training the model, you will need a training set and for testing or evaluating the test dataset's performance. Thus, you have to decide. Here, we pick the first 80 days of the year for training and test the model to predict the later days."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsLzrLwm0zZM"
      },
      "outputs": [],
      "source": [
        "# step 5: Finalize the data, and split training and testing data\n",
        "ts_train = ts[ts.DayofYear <= 80]\n",
        "ts_test = ts[ts.DayofYear > 80]\n",
        "ts = ts[['T', 'T_1', 'T_2', 'T_3']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L9_g0X_m3k5"
      },
      "source": [
        "#### Data Exploration\n",
        "Exploring the data before training is vital for handling missing or outlier values and identifying correlations between features that could be used for predicting others. You may already have experience with such exploration from statistical modeling with linear regression. In this case, correlations between time intervals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGJVvJ98m6wV"
      },
      "outputs": [],
      "source": [
        "desc_stat = ts.describe()\n",
        "desc_stat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23GNPRGGm-a0"
      },
      "outputs": [],
      "source": [
        "# II. Distribution and scatter plots\n",
        "sns.pairplot(ts)   # pair plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFEeJV3TnDww"
      },
      "outputs": [],
      "source": [
        "ts_corr = ts.corr()\n",
        "sns.heatmap(ts_corr)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zkTECiLnXRm"
      },
      "source": [
        "#### Data preparation for machine learning models\n",
        "In this example, we consider only two past time-intervals and thus create new sub-sets of train and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u_UDKKXnc3-"
      },
      "outputs": [],
      "source": [
        "X_train = ts_train[['T_1', 'T_2']]\n",
        "y_train = ts_train['T']\n",
        "\n",
        "X_test = ts_test[['T_1', 'T_2']]\n",
        "y_test = ts_test['T']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41ZZ0mW1nqDI"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# train and predict\n",
        "tree_regressor = DecisionTreeRegressor() # # here we just change parameter 'max_depth'\n",
        "tree_regressor.fit(X_train, y_train)\n",
        "y_pred_tree = tree_regressor.predict(X_test)\n",
        "\n",
        "# compare the prediction and the true value\n",
        "x = range(len(y_test))\n",
        "plt.plot(x, y_test, label='True', alpha = 0.7)\n",
        "plt.plot(x, y_pred_tree, label='Tree Prediciton', alpha = 0.7)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# evaluation - smaller is better\n",
        "tree_mse = mean_squared_error(y_test, y_pred_tree)\n",
        "print(tree_mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFYPGyuwpytr"
      },
      "source": [
        "Always check your ML model to see what parameters need to be calibrated. Check the Decision Tree model and its parameters. [DT model](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1F6yyXCQne7r"
      },
      "outputs": [],
      "source": [
        "# Tune the parameters of decision tree, then train and predict\n",
        "# train and predict\n",
        "best_t = None\n",
        "for i in range(1,10):\n",
        "    tree_regressor = DecisionTreeRegressor(max_depth=i, random_state=45, splitter = 'random') # # here we just change parameter 'max_depth'\n",
        "    tree_regressor.fit(X_train, y_train)\n",
        "    y_pred_tree = tree_regressor.predict(X_test)\n",
        "    # evaluation - smaller is better\n",
        "    tree_mse = mean_squared_error(y_test, y_pred_tree)\n",
        "    if best_t is None or best_t > tree_mse:\n",
        "      best_t = tree_mse\n",
        "print('best tree mse',best_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGrWGFZIp8g2"
      },
      "source": [
        "[RF model](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYAS81PEoQuz"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "best_t = None\n",
        "n_estimators = [10,20,50,100,200,500]\n",
        "depths = [1,2,5,10,20,30]\n",
        "for i in range(0,len(depths)-1):\n",
        "  for j in range(0,len(n_estimators)-1):\n",
        "    tree_regressor = RandomForestRegressor(max_depth=depths[i], n_estimators = n_estimators[j]) # # here we just change parameter 'max_depth'\n",
        "    tree_regressor.fit(X_train, y_train)\n",
        "    y_pred_tree = tree_regressor.predict(X_test)\n",
        "    # evaluation - smaller is better\n",
        "    tree_mse = mean_squared_error(y_test, y_pred_tree)\n",
        "    if best_t is None or best_t > tree_mse:\n",
        "      best_t = tree_mse\n",
        "print('best tree mse',best_t)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THBRI-ph2r8k"
      },
      "outputs": [],
      "source": [
        "best_t = None\n",
        "#n_estimators = [10,20,50,100,200,500]\n",
        "#depths = [1,2,5,10,20,30]\n",
        "for i in range(1,100):\n",
        "  for j in range(1,20):\n",
        "    tree_regressor = RandomForestRegressor(max_depth=i, n_estimators = j) # # here we just change parameter 'max_depth'\n",
        "    tree_regressor.fit(X_train, y_train)\n",
        "    y_pred_tree = tree_regressor.predict(X_test)\n",
        "    # evaluation - smaller is better\n",
        "    tree_mse = mean_squared_error(y_test, y_pred_tree)\n",
        "    if best_t is None or best_t > tree_mse:\n",
        "      best_t = tree_mse\n",
        "print('best tree mse',best_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbY7hCtwkxCD"
      },
      "source": [
        "# Appedning - Part 2 - Descriptive statistics and visualizations (for your reference; not covered during exercise)\n",
        "This part of the appendix gives you an example of visualization and descriptive statistics. It is not covered during the exercise, but you may explore and reuse the code during the course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAnPiOjE3YJH"
      },
      "source": [
        "Loading additional dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emjNJOkS3WNr"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet('NY_taxi_2017Mar_09-11.parquet', engine='fastparquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q2DyOmekswi"
      },
      "outputs": [],
      "source": [
        "col_of_interest = ['passenger_count', 'trip_distance', 'fare_amount', 'tip_amount', 'total_amount']\n",
        "desc_stat_com = df[col_of_interest].describe()\n",
        "desc_stat_com = desc_stat_com.round(2)   # keep 2 decimals of the float value\n",
        "desc_stat_com.head(5)  # show the first 5 line of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee4uoLjAlDuo"
      },
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yf_SA3953cs"
      },
      "source": [
        "Line plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bNO28MUlG8E"
      },
      "outputs": [],
      "source": [
        "plt.style.use('ggplot')  # set visualization style\n",
        "df['hour'] = pd.to_datetime(df.tpep_pickup_datetime).dt.hour\n",
        "# get the sum number of each column by hour\n",
        "df_hour_sum = df.groupby(['hour']).sum()  # refer to https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html\n",
        "df_hour_sum.plot(y=['trip_distance'], kind='line', figsize=(12, 9), legend=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3Iktu6T5zds"
      },
      "source": [
        "Histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMahUIinlRKj"
      },
      "outputs": [],
      "source": [
        "df_hour_sum.hist(column=['trip_distance'], figsize=(12, 9), legend=True, bins=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4324TApu56E2"
      },
      "source": [
        "Box plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6bLT5H0lTIS"
      },
      "outputs": [],
      "source": [
        "df.boxplot(column='passenger_count', by='date', showfliers=True, figsize=(8, 6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hksHkfmlliY"
      },
      "source": [
        "### Spatial visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTL0BAysljTK"
      },
      "outputs": [],
      "source": [
        "# refer to https://medium.com/@haonanzhong/new-york-city-taxi-data-analysis-286e08b174a1\n",
        "# Read in the taxi zone shapefile\n",
        "import geopandas as gpd\n",
        "import matplotlib.colors as colors\n",
        "\n",
        "sf = gpd.read_file('taxi_zones.shp')\n",
        "sf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5ICIeILltjZ"
      },
      "outputs": [],
      "source": [
        "# Compute pickup and dropoff amount of each zone\n",
        "pu_zone = df.groupby(['PULocationID'], as_index=False).size()  # refer to https://favtutor.com/blogs/pandas-groupby-count\n",
        "do_zone = df.groupby(['DOLocationID'], as_index=False).size()\n",
        "pu_zone = gpd.GeoDataFrame(pd.merge(pu_zone, sf, left_on='PULocationID', right_on='LocationID')).drop('LocationID', axis=1)\n",
        "do_zone = gpd.GeoDataFrame(pd.merge(do_zone, sf, left_on='DOLocationID', right_on='LocationID')).drop('LocationID', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6SumBfAlyq9"
      },
      "outputs": [],
      "source": [
        "# plot geospatial visualisation to compare pickup and dropoff amount from each zone\n",
        "fig, axs = plt.subplots(ncols=2, figsize=(20, 10))\n",
        "fig.subplots_adjust(bottom=0.1, top=0.9, left=0.09, right=0.8, wspace=0.02, hspace=0.02)\n",
        "# create a normalized colorbar\n",
        "vmin, vmax = pu_zone['size'].min(), pu_zone['size'].max()\n",
        "axs[0] = pu_zone.plot(column='size', linewidth=0.09, edgecolor='k', figsize=(10, 10), norm=colors.LogNorm(vmin=vmin, vmax=vmax), cmap='Reds', legend=False, ax=axs[0])\n",
        "#ctx.add_basemap(axs[0])\n",
        "vmin, vmax = do_zone['size'].min(), do_zone['size'].max()\n",
        "axs[1] = do_zone.plot(column='size', linewidth=0.1, edgecolor='k', figsize=(10, 10),\n",
        "    norm=colors.LogNorm(vmin=vmin, vmax=vmax), cmap='Reds', legend=False, ax=axs[1])\n",
        "#ctx.add_basemap(axs[1])\n",
        "axs[0].set_title('Pickup')\n",
        "axs[1].set_title('Dropoff')\n",
        "axs[0].set_axis_off()\n",
        "axs[1].set_axis_off()\n",
        "# draw the color bar\n",
        "patch_col = axs[0].collections[0]\n",
        "cb = fig.colorbar(patch_col, ax=axs, shrink=0.72, orientation=\"vertical\", pad=0.005)\n",
        "cb.ax.set_ylabel('Trip Amount')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "sbY7hCtwkxCD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}